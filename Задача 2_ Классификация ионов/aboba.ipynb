{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f74faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy\n",
    "import os\n",
    "import dimod\n",
    "from dwave.samplers import SimulatedAnnealingSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a13338",
   "metadata": {},
   "source": [
    "## Внимание, делаем по следующей статье!\n",
    "https://www.arxiv-vanity.com/papers/0804.4457/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb455093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "S1, S2 = 1, 40\n",
    "T_feat, T_geom = 0.8, 0.7\n",
    "# reading the image in grayscale mode\n",
    "gray = cv2.imread('Data\\\\760e3945-e0c9-4c9a-b78a-a68fbbee05cd.png', 0)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0f23c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = pd.read_csv('labeled_ions_team_name_1.csv', sep=';')\n",
    "load_data = lambda x: cv2.imread('Data\\\\'+x,0)\n",
    "lab['sum'] = lab.iloc[:,2:].apply(np.sum, axis=1)\n",
    "lab_arr = []\n",
    "for i in lab['Filename']:\n",
    "    out = load_data(i)\n",
    "    #out = cv2.medianBlur(out, 3)\n",
    "    out = cv2.GaussianBlur(out, (5, 5), 0)\n",
    "    lab_arr.append(out)           \n",
    "\n",
    "#def find_cent()\n",
    "def find_points(gray, s1=S1, s2=S2):\n",
    "    # findcontours \n",
    "    # threshold \n",
    "    th, threshed = cv2.threshold(gray, 10, 255,  \n",
    "          cv2.THRESH_BINARY|cv2.THRESH_OTSU) \n",
    "\n",
    "    cnts = cv2.findContours(threshed, cv2.RETR_LIST,  \n",
    "                    cv2.CHAIN_APPROX_SIMPLE)[-2] \n",
    "\n",
    "    # filter by area \n",
    "    xcnts = [] \n",
    "    for cnt in cnts: \n",
    "        if s1<cv2.contourArea(cnt) <s2: \n",
    "            xcnts.append(cnt)\n",
    "        \n",
    "    return xcnts\n",
    "\n",
    "# Функции для создания вектора признаков из списка массивов\n",
    "def make_feat_vec(lab_arr, s1=S1):\n",
    "    res = []\n",
    "    for j in range(len(lab_arr)):\n",
    "        matrix = find_points(lab_arr[j], s1=s1)\n",
    "        out = []\n",
    "        for i in range(len(matrix)):\n",
    "           out.append( np.sum(matrix[i], axis=0)/len(matrix[i]) )\n",
    "        if len(out) == 0:\n",
    "            res.append(None)\n",
    "        else:\n",
    "            res.append(np.vstack(out))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3900c",
   "metadata": {},
   "source": [
    "## Осторожно\n",
    "Подбор параметра s1 из цикла, который отвечает за области со слишком малой площадью. Как можно увидеть, мы не смогли варируя\n",
    "только 1 параметр добиться ошибки меньше 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69cc214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 \t 10.009999999999994\n"
     ]
    }
   ],
   "source": [
    "hist =[]\n",
    "s1_array = np.arange (0.1, 20, 0.01)\n",
    "for i in s1_array:\n",
    "    out = make_feat_vec(lab_arr, s1=i)\n",
    "    out = np.array(list(map(len, out)))\n",
    "    pen = np.sum((lab['sum'] - out)**2)\n",
    "    hist.append(pen)\n",
    "a = min(hist)\n",
    "S1 = s1_array[hist.index(a)]\n",
    "print(a,'\\t',S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "081e5eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31.1043956 , 133.03296703],\n",
       "       [ 29.63729604,  94.1995338 ],\n",
       "       [ 29.66666667,  59.04285714],\n",
       "       [ 28.44444444,  20.56296296]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = make_feat_vec(lab_arr, s1=S1)\n",
    "comp_mat = (temp[8] + temp[6] + temp[5])/3\n",
    "comp_label = [1,2,3,4] #Узнал при помощи ручного сопоставления. Так быстрее!\n",
    "comp_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f57ca737",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.fsencode('Data')\n",
    "file_names = ['Data\\\\' + os.fsdecode(file) for file in os.listdir(directory)]\n",
    "lab_arr = []\n",
    "for i in os.listdir(directory):\n",
    "    out = load_data(os.fsdecode(i))\n",
    "    #out = cv2.medianBlur(out, 3)\n",
    "    out = cv2.GaussianBlur(out, (5, 5), 0)\n",
    "    lab_arr.append(out)  \n",
    "    \n",
    "data_list = make_feat_vec(lab_arr, s1=S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "385eb106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Нормированое скалярное произведение\n",
    "def dumb_ass(row1, row2):\n",
    "    return np.dot(row1, row2)/(np.linalg.norm(row1)*np.linalg.norm(row2))\n",
    "\n",
    "# Граф с ребрами чьи веса равны норме выше  \n",
    "def make_graph(elem_mat, comp_mat):\n",
    "    res = np.zeros((len(elem_mat), 4))\n",
    "    for j in (0,1,2,3):\n",
    "        for i in range(len(elem_mat)):\n",
    "            row1 = comp_mat[j]\n",
    "            row2 = elem_mat[i]\n",
    "            out = dumb_ass(row1, row2)\n",
    "            if out > T_feat:       \n",
    "                res[i,j] = out\n",
    "    return res\n",
    "\n",
    "# Проврека на то, что элмент соотвестует\n",
    "# вершинам с одним обшим индексом из исходного графа\n",
    "def chek(i, j):\n",
    "    out = False\n",
    "    if i in range(j//4*4, j//4*4+4):\n",
    "        out = True\n",
    "    return out\n",
    "\n",
    "# Получение матрицы кубо, где мы сразу делаем матрицу несоотвествия\n",
    "# и заменяем элементы в соответствии с правилами из статьи\n",
    "def make_qubo(elem_mat, comp_mat):\n",
    "    mat = make_graph(elem_mat, comp_mat)\n",
    "    len1 = len(elem_mat)\n",
    "    vec = mat.flatten()\n",
    "    lenin = len(vec)\n",
    "    vec = vec.reshape(1,-1)\n",
    "    res = vec.T@vec\n",
    "\n",
    "    for i in range(lenin):\n",
    "        for j in range(lenin):\n",
    "            if i == j:\n",
    "                res[i,j] = -1\n",
    "            elif ((res[i,j] < T_geom) or chek(i,j) or chek(j,i)) and res[i,j] !=0:\n",
    "                res[i,j] = 1\n",
    "            else:\n",
    "                res[i,j] = 0\n",
    "    res[res == 1] = lenin\n",
    "    return res\n",
    "\n",
    "''' Недоделанный вариант где мы должны были не умножать евлкидовы нормы для \n",
    "каждых элементов матрицы несогласованости, а честно считать нормы заново в \n",
    "соотвесвии с векторами трансляции, как было указано в исходной статье \n",
    "(наверное, они точно не указали).\n",
    "'''\n",
    "\n",
    "def get_indexes (i, j, len1):\n",
    "    return (i//len1, (j+1)%4, i//len1, j//4)\n",
    "    \n",
    "def make_qubo1(elem_mat, comp_mat):\n",
    "    mat = make_graph(elem_mat, comp_mat)\n",
    "    len1 = len(elem_mat)\n",
    "    vec = mat.flatten()\n",
    "    lenin = len(vec)\n",
    "    res = np.zeros((lenin, lenin))\n",
    "    \n",
    "    for i in range(lenin):\n",
    "        for j in range(lenin):\n",
    "            i1, j1, i2, j2, = get_indexes(i, j, len1)\n",
    "            d1 = dumb_ass(elem_mat[i1], elem_mat[i2])\n",
    "            d2 = dumb_ass(comp_mat[j1], comp_mat[j2])\n",
    "            res[i,j] = d1*d2\n",
    "            if i == j:\n",
    "                res[i,j] = -1\n",
    "            elif ((res[i,j] < T_geom) or chek(i,j) or chek(j,i)) and res[i,j] !=0:\n",
    "                res[i,j] = 1\n",
    "            else:\n",
    "                res[i,j] = 0\n",
    "    res[res == 1] = lenin\n",
    "    return res\n",
    "    \n",
    "#Проверка на симметричность матрицы \n",
    "check_elem = make_qubo(data_list[10], comp_mat)\n",
    "np.all(check_elem==check_elem.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45df6b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.80911672, 0.89276411, 0.99992933]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_graph(data_list[10], comp_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4ab8515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  0.,  0.,  0.],\n",
       "       [ 0., -1.,  4.,  4.],\n",
       "       [ 0.,  4., -1.,  4.],\n",
       "       [ 0.,  4.,  4., -1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_qubo(data_list[10], comp_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2f09e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 0, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_indexes (4, 4, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bb4f73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  4.]\n",
      " [ 0.  0.  4. -1.]] \n",
      "\n",
      " [[28.64705882 20.47058824]]\n"
     ]
    }
   ],
   "source": [
    "elem = data_list[212]\n",
    "check_elem = make_qubo(elem, comp_mat)\n",
    "print(check_elem, '\\n\\n' ,elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edbbd3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  9,  10,  44,  54,  80, 145, 160, 212, 222, 273, 299, 305, 339,\n",
       "        468, 545, 548, 639, 715, 762, 783, 810, 845, 859, 885, 898, 963,\n",
       "        968, 990, 999], dtype=int64),)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irb = lambda x: len(x) if not (x is None) else 0\n",
    "soska = np.array(list(map(irb, data_list)))\n",
    "np.where(soska == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4cc6a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2  3 energy num_oc.\n",
      "0   1  1  0  1   -3.0       1\n",
      "1   1  1  0  1   -3.0       1\n",
      "2   1  1  0  1   -3.0       1\n",
      "3   1  1  0  1   -3.0       1\n",
      "4   1  1  1  0   -3.0       1\n",
      "5   1  1  0  1   -3.0       1\n",
      "6   1  1  0  1   -3.0       1\n",
      "7   1  1  0  1   -3.0       1\n",
      "8   1  1  1  0   -3.0       1\n",
      "9   1  1  0  1   -3.0       1\n",
      "10  1  1  0  1   -3.0       1\n",
      "11  1  1  1  0   -3.0       1\n",
      "12  1  1  1  0   -3.0       1\n",
      "13  1  1  1  0   -3.0       1\n",
      "14  1  1  1  0   -3.0       1\n",
      "15  1  1  0  1   -3.0       1\n",
      "16  1  1  0  1   -3.0       1\n",
      "17  1  1  0  1   -3.0       1\n",
      "18  1  1  0  1   -3.0       1\n",
      "19  1  1  1  0   -3.0       1\n",
      "20  1  1  0  1   -3.0       1\n",
      "21  1  1  1  0   -3.0       1\n",
      "22  1  1  1  0   -3.0       1\n",
      "23  1  1  1  0   -3.0       1\n",
      "24  1  1  1  0   -3.0       1\n",
      "25  1  1  1  0   -3.0       1\n",
      "26  1  1  0  1   -3.0       1\n",
      "27  1  1  1  0   -3.0       1\n",
      "28  1  1  0  1   -3.0       1\n",
      "29  1  1  1  0   -3.0       1\n",
      "30  1  1  1  0   -3.0       1\n",
      "31  1  1  0  1   -3.0       1\n",
      "32  1  1  1  0   -3.0       1\n",
      "33  1  1  1  0   -3.0       1\n",
      "34  1  1  0  1   -3.0       1\n",
      "35  1  1  0  1   -3.0       1\n",
      "36  1  1  0  1   -3.0       1\n",
      "37  1  1  1  0   -3.0       1\n",
      "38  1  1  0  1   -3.0       1\n",
      "39  1  1  1  0   -3.0       1\n",
      "40  1  1  1  0   -3.0       1\n",
      "41  1  1  0  1   -3.0       1\n",
      "42  1  1  1  0   -3.0       1\n",
      "43  1  1  0  1   -3.0       1\n",
      "44  1  1  1  0   -3.0       1\n",
      "45  1  1  0  1   -3.0       1\n",
      "46  1  1  0  1   -3.0       1\n",
      "47  1  1  1  0   -3.0       1\n",
      "48  1  1  1  0   -3.0       1\n",
      "49  1  1  1  0   -3.0       1\n",
      "50  1  1  1  0   -3.0       1\n",
      "51  1  1  1  0   -3.0       1\n",
      "52  1  1  1  0   -3.0       1\n",
      "53  1  1  0  1   -3.0       1\n",
      "54  1  1  1  0   -3.0       1\n",
      "55  1  1  1  0   -3.0       1\n",
      "56  1  1  1  0   -3.0       1\n",
      "57  1  1  0  1   -3.0       1\n",
      "58  1  1  1  0   -3.0       1\n",
      "59  1  1  1  0   -3.0       1\n",
      "60  1  1  0  1   -3.0       1\n",
      "61  1  1  0  1   -3.0       1\n",
      "62  1  1  1  0   -3.0       1\n",
      "63  1  1  0  1   -3.0       1\n",
      "64  1  1  0  1   -3.0       1\n",
      "65  1  1  1  0   -3.0       1\n",
      "66  1  1  0  1   -3.0       1\n",
      "67  1  1  1  0   -3.0       1\n",
      "68  1  1  0  1   -3.0       1\n",
      "69  1  1  0  1   -3.0       1\n",
      "70  1  1  0  1   -3.0       1\n",
      "71  1  1  1  0   -3.0       1\n",
      "72  1  1  1  0   -3.0       1\n",
      "73  1  1  1  0   -3.0       1\n",
      "74  1  1  0  1   -3.0       1\n",
      "75  1  1  0  1   -3.0       1\n",
      "76  1  1  1  0   -3.0       1\n",
      "77  1  1  0  1   -3.0       1\n",
      "78  1  1  0  1   -3.0       1\n",
      "79  1  1  0  1   -3.0       1\n",
      "80  1  1  1  0   -3.0       1\n",
      "81  1  1  0  1   -3.0       1\n",
      "82  1  1  0  1   -3.0       1\n",
      "83  1  1  0  1   -3.0       1\n",
      "84  1  1  0  1   -3.0       1\n",
      "85  1  1  1  0   -3.0       1\n",
      "86  1  1  1  0   -3.0       1\n",
      "87  1  1  1  0   -3.0       1\n",
      "88  1  1  1  0   -3.0       1\n",
      "89  1  1  0  1   -3.0       1\n",
      "90  1  1  1  0   -3.0       1\n",
      "91  1  1  1  0   -3.0       1\n",
      "92  1  1  0  1   -3.0       1\n",
      "93  1  1  0  1   -3.0       1\n",
      "94  1  1  0  1   -3.0       1\n",
      "95  1  1  1  0   -3.0       1\n",
      "96  1  1  0  1   -3.0       1\n",
      "97  1  1  1  0   -3.0       1\n",
      "98  1  1  1  0   -3.0       1\n",
      "99  1  1  0  1   -3.0       1\n",
      "['BINARY', 100 rows, 100 samples, 4 variables] \n",
      "\n",
      " Вероятность\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.63245553, 0.63245553, 0.31622777, 0.31622777])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' У нас получилось множество ответов с одинаковой энергией. По этой причине мы решили собирать статистику для \n",
    "нахождения вероятностей\n",
    "'''\n",
    "sampler = SimulatedAnnealingSampler()\n",
    "qubo = check_elem\n",
    "sampleset = sampler.sample_qubo(qubo, num_reads = 100)\n",
    "a = list(sampleset.samples())\n",
    "aboba = lambda x: np.array(list(dict(x).values()))\n",
    "a = list(map(aboba, a))\n",
    "a = np.add.reduce(a)\n",
    "a = a.astype(float)\n",
    "a /= np.linalg.norm(a)\n",
    "print(sampleset,'\\n\\n','Вероятность')\n",
    "\n",
    "a # вероятности для каждого состояния\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0222c43",
   "metadata": {},
   "source": [
    "## Рассуждения\n",
    "Как можно увидеть у нас не получился работоспособный код. Только когда 1 точка, мы получаем, по статистике, что он находит нужный нам элемент (место в битовой строке). Возможные причины мы видим в следующем:\n",
    "1) Неправильные нормы. Дело в том, что в оригинале статьи не раскрываются какие нормы на каждом этапе используются, а только указывается каким требованиям они должны удовлетворять.\n",
    "2) Не полное понимание интерпритации полученного бинарного вектора.\n",
    "3) Мы тупики.\n",
    "\n",
    "Однако у нас получилось найти точки интереса и сделать из них вектор признаков с погрешностью около 1-2%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
